---
title: "A High-Performance CNN Method for Offline Handwritten Chinese Character Recognition and Visualization"
authors:
- admin
- Zhiqiang You
- Keqin Lin

author_notes:

date: "2020-05-30T00:00:00Z"
modified: 2024-10-23
doi: "https://doi.org/10.1007/s00500-019-04083-3"

# Schedule page publish date (NOT publication's date).
publishDate: "2024-10-22T00:00:00Z"

# Publication type.
# Accepts a single type but formatted as a YAML list (for Hugo requirements).
# Enter a publication type from the CSL standard.
publication_types: ["article-journal"]

# Publication name and optional abbreviated publication name.
publication: "In *Soft Computing*"
publication_short: "*Soft Computing*"

abstract: ''

# Summary. An optional shortened abstract.
summary: ""

tags:
  - OCR 
  - Handwritten Character Recognition
  - CNNs
  
featured: true

links:
- name: "arXiv"
  url: "https://arxiv.org/abs/1812.11489"
url_pdf: https://link.springer.com/epdf/10.1007/s00500-019-04083-3?author_access_token=T-sw5xcr57JE5_pjR_0Vrfe4RwlQNchNByi7wbcMAY41mDQ1UaWmo8QPg956ZHdrtrmysrl25HcwHd_A88dKPwGVxqZNMX_11svHZz3nsyAJi6AsN1rom1xQCF-fjGaVhL2dyzXTk3AXOjmqDvg2pg%3D%3D
url_code: 'https://github.com/pavlo-melnyk/offline-HCCR'
url_dataset: ''
url_poster: ''
url_project: ''
url_slides: ''
url_source: ''
url_video: ''

# Featured image
# To use, add an image named `featured.jpg/png` to your page's folder. 
image:
  caption: 
  focal_point: ""
  preview_only: false

# Associated Projects (optional).
#   Associate this publication with one or more of your projects.
#   Simply enter your project's folder or file name without extension.
#   E.g. `internal-project` references `content/project/internal-project/index.md`.
#   Otherwise, set `projects: []`.
projects: []

# Slides (optional).
#   Associate this publication with Markdown slides.
#   Simply enter your slide deck's filename without extension.
#   E.g. `slides: "example"` references `content/slides/example/index.md`.
#   Otherwise, set `slides: ""`.
slides: ""
---

<span style="display:none;"> Recent researches introduced fast, compact and efficient convolutional neural networks (CNNs) for offline handwritten Chinese character recognition (HCCR). However, many of them did not address the problem of network interpretability. We propose a new architecture of a deep CNN with high recognition performance which is capable of learning deep features for visualization. A special characteristic of our model is the bottleneck layers which enable us to retain its expressiveness while reducing the number of multiply-accumulate operations and the required storage. We introduce a modification of global weighted average pooling (GWAP) - global weighted output average pooling (GWOAP). This paper demonstrates how they allow us to calculate class activation maps (CAMs) in order to indicate the most relevant input character image regions used by our CNN to identify a certain class. Evaluating on the ICDAR-2013 offline HCCR competition dataset, we show that our model enables a relative 0.83% error reduction while having 49% fewer parameters and the same computational cost compared to the current state-of-the-art single-network method trained only on handwritten data. Our solution outperforms even recent residual learning approaches. </span>