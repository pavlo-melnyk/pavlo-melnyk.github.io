<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Point Clouds | Pavlo Melnyk</title>
    <link>//localhost:1313/tags/point-clouds/</link>
      <atom:link href="//localhost:1313/tags/point-clouds/index.xml" rel="self" type="application/rss+xml" />
    <description>Point Clouds</description>
    <generator>Hugo Blox Builder (https://hugoblox.com)</generator><language>en-us</language><lastBuildDate>Mon, 17 Jun 2024 00:00:00 +0000</lastBuildDate>
    <image>
      <url>//localhost:1313/media/icon_hu10934838655842282239.png</url>
      <title>Point Clouds</title>
      <link>//localhost:1313/tags/point-clouds/</link>
    </image>
    
    <item>
      <title>TetraSphere: A Neural Descriptor for O(3)-Invariant Point Cloud Analysis</title>
      <link>//localhost:1313/publication/tetrasphere/</link>
      <pubDate>Mon, 17 Jun 2024 00:00:00 +0000</pubDate>
      <guid>//localhost:1313/publication/tetrasphere/</guid>
      <description>&lt;p&gt;&lt;span style=&#34;display:none;&#34;&gt; In many practical applications 3D point cloud analysis requires rotation invariance. In this paper we present a learnable descriptor invariant under 3D rotations and reflections i.e. the O(3) actions utilizing the recently introduced steerable 3D spherical neurons and vector neurons. Specifically we propose an embedding of the 3D spherical neurons into 4D vector neurons which leverages end-to-end training of the model. In our approach we perform TetraTransform&amp;mdash;an equivariant embedding of the 3D input into 4D constructed from the steerable neurons&amp;mdash;and extract deeper O(3)-equivariant features using vector neurons. This integration of the TetraTransform into the VN-DGCNN framework termed TetraSphere negligibly increases the number of parameters by less than 0.0002%. TetraSphere sets a new state-of-the-art performance classifying randomly rotated real-world object scans of the challenging subsets of ScanObjectNN. Additionally TetraSphere outperforms all equivariant methods on randomly rotated synthetic data: classifying objects from ModelNet40 and segmenting parts of the ShapeNet shapes. Thus our results reveal the practical value of steerable 3D spherical neurons for learning in 3D Euclidean space. &lt;/span&gt;&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
